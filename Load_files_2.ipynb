{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generating data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "from npl import bootstrap_logreg as bbl\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "from npl.evaluate import logreg_ll as lrl\n",
    "\n",
    "\n",
    "\n",
    "n_iter=5\n",
    "\n",
    "def gen_toy(N_data, beta, intercept=2, seed=100):\n",
    "    #def run_HDP_NPL(datasets, method, alpha, beta, params):\n",
    "    #run_HDP_NPL([d1, d2, d3], method=‘RandomForest’, alpha=0.1, gamma=2., params={num_trees: 3, tree_depth: 5})\n",
    "    #run_HDP_NPL([d1, d2, d3,d4], method=‘LogisticRegression’, alpha=0.1, gamma=2., params={regularizer:None})\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    K_set=len(N_data)\n",
    "    X=[]\n",
    "    \n",
    "    for ss in range(K_set):\n",
    "        X.append(np.random.multivariate_normal(beta[ss], [[1,0],[0,1]], N_data[ss]))\n",
    "    \n",
    "    Linear_part=[]\n",
    "    eta=[]\n",
    "    y=[]\n",
    "    \n",
    "    for i in range(K_set):\n",
    "        Linear_part.append(X[i]@beta[i]+intercept*np.ones(N_data[i]))\n",
    "        eta.append(1/(1 + np.exp(-Linear_part[i])))\n",
    "        y.append(np.random.binomial(1,eta[i]))\n",
    "    \n",
    "    gamma=[1/b for b in N_data ]\n",
    "    \n",
    "    return X, y, gamma\n",
    "\n",
    "\n",
    "def gen_test_toy(N_test_data, beta, intercept=2, seed=100):\n",
    "    #def run_HDP_NPL(datasets, method, alpha, beta, params):\n",
    "    #run_HDP_NPL([d1, d2, d3], method=‘RandomForest’, alpha=0.1, gamma=2., params={num_trees: 3, tree_depth: 5})\n",
    "    #run_HDP_NPL([d1, d2, d3,d4], method=‘LogisticRegression’, alpha=0.1, gamma=2., params={regularizer:None})\n",
    "    \n",
    "    np.random.seed(seed+10101)\n",
    "    \n",
    "    K_set=len(N_test_data)\n",
    "    \n",
    "    X=[]\n",
    "    \n",
    "    for i in range(K_set):\n",
    "        X.append(np.random.multivariate_normal(beta[i], [[1,0],[0,1]], N_test_data[i]))\n",
    "        \n",
    "    Linear_part=[]\n",
    "    eta=[]\n",
    "    y=[]\n",
    "    \n",
    "    for i in range(K_set):\n",
    "        Linear_part.append(X[i]@beta[i]+intercept*np.ones(N_test_data[i]))\n",
    "        eta.append(1/(1 + np.exp(-Linear_part[i])))\n",
    "        y.append(np.random.binomial(1,eta[i]))\n",
    "    \n",
    "    gamma=[1/b for b in N_test_data ]\n",
    "    \n",
    "    return X, y, gamma\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 12/1000 [00:00<00:13, 73.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 24/1000 [00:01<00:49, 19.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 60/1000 [00:01<00:34, 27.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 156/1000 [00:02<00:21, 38.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 300/1000 [00:02<00:12, 54.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███▉      | 396/1000 [00:02<00:08, 75.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 492/1000 [00:02<00:04, 101.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████▉    | 588/1000 [00:02<00:03, 135.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 684/1000 [00:02<00:01, 175.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 780/1000 [00:02<00:00, 223.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 876/1000 [00:03<00:00, 262.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 291.60it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 72/1000 [00:00<00:01, 617.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 168/1000 [00:00<00:01, 642.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 685.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 681.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 660.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 612.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 539.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 482.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 596.75it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 944.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 961.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 821.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 780.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 693.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 591.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 539.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 526.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 612.87it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 9.130327939987183\n",
      "9.130327939987183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 72/1000 [00:00<00:01, 634.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 168/1000 [00:00<00:01, 606.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 647.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 590.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 543.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:01<00:00, 573.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 595.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 616.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 646.22it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 947.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 885.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 693.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 605.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 551.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:01<00:00, 571.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 584.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 599.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 644.99it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 72/1000 [00:00<00:01, 656.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 168/1000 [00:00<00:01, 638.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 691.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 813.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:00<00:00, 768.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 775.69it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 7.306169033050537\n",
      "7.306169033050537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:01, 851.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 897.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 790.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 744.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 718.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 640.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 654.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 634.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 713.37it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 1011.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 1041.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 832.14it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 768.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 793.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 782.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:00<00:00, 667.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 664.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 760.27it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 1022.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 1034.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 916.75it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 856.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 796.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 773.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:00<00:00, 747.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 683.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 787.93it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 6.13362717628479\n",
      "6.13362717628479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 989.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 1006.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 897.52it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 830.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 792.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 778.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:00<00:00, 739.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 669.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 776.95it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 1101.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 1097.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 960.03it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 945.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:00<00:00, 770.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 777.68it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 915.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 935.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 854.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 934.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:00<00:00, 794.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 813.40it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 6.386575222015381\n",
      "6.386575222015381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 72/1000 [00:00<00:01, 564.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 168/1000 [00:00<00:01, 609.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 670.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 599.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 498.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:01<00:00, 481.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 499.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 550.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 605.39it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 48/1000 [00:00<00:03, 277.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 168/1000 [00:00<00:02, 344.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:01, 387.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:01, 398.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:01<00:01, 379.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:01<00:00, 403.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 441.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 490.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 538.15it/s][A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 120/1000 [00:00<00:00, 911.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 264/1000 [00:00<00:00, 922.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 360/1000 [00:00<00:00, 847.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 456/1000 [00:00<00:00, 743.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 552/1000 [00:00<00:00, 717.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▍   | 648/1000 [00:00<00:00, 644.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 744/1000 [00:01<00:00, 534.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▍ | 840/1000 [00:01<00:00, 533.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 659.22it/s][A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 7.349469900131226\n",
      "7.349469900131226\n"
     ]
    }
   ],
   "source": [
    "def main(beta, intercept, B_postsamples):\n",
    "    \n",
    "\n",
    "    T_trunc = 100\n",
    "    a=1\n",
    "    b = 1 #rate of gamma hyperprior\n",
    "    \n",
    "    alph_conc=0 # D ~ DP(alpha_conc, H)\n",
    "    alpha_top_layer=0 # Dk ~ DP(alpha_top_layer, D)\n",
    "    N_data=[1000,2000,5000]\n",
    "    D_data=len(beta[0])\n",
    "    \n",
    "    K_set=len(beta)\n",
    "    \n",
    "    \n",
    "    for i in range(n_iter):\n",
    "\n",
    "        seed = 100+i\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        x, y, gamma = gen_toy(N_data, beta, intercept, seed)\n",
    "        \n",
    "        #y,x,alph_conc,gamma,N_data,D_data = load_data(dataset,seed)\n",
    "\n",
    "        start= time.time()\n",
    "        #carry out posterior bootstrap\n",
    "        temp = bbl.bootstrap_logreg(B_postsamples,alph_conc,alpha_top_layer,T_trunc,y,x,N_data,D_data,a,b,gamma)\n",
    "        end = time.time()\n",
    "        print ('Time elapsed = {}'.format(end - start))\n",
    "        \n",
    "        \n",
    "        \n",
    "        beta_bb=[]\n",
    "        ll_bb=[]\n",
    "        \n",
    "        for j in range(K_set):\n",
    "            beta_b=np.zeros((B_postsamples,K_set))\n",
    "            ll_b=[]\n",
    "            for bb in range(B_postsamples):\n",
    "                beta_b[bb]=temp[j][bb][0]\n",
    "                ll_b.append(temp[j][bb][1])\n",
    "            beta_bb.append(beta_b)\n",
    "            ll_bb.append(ll_b)\n",
    "        \n",
    "        \n",
    "\n",
    "        #convert to dataframe and save\n",
    "        dict_bb = {'beta': beta_bb, 'll': ll_bb, 'time': end-start}\n",
    "        par_bb = pd.Series(data = dict_bb)\n",
    "        print(par_bb['time'])\n",
    "        \n",
    "        par_bb.to_pickle('./parameters/par_bb_logreg_c{}_a{}_b{}_gN_pol_B{}_seed{}'.format(alph_conc,a,b,B_postsamples,seed))\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main([np.array([-1,1]),np.array([-1,1]),np.array([-1,1])],2,1000)\n",
    "    #main([np.array([1,5]),np.array([-1,7]),np.array([9,-1])],2,1000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, _=gen_test_toy([1000,1000,1000], [np.array([0,0]),np.array([-1,1]),np.array([1,-1])],2,12121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR DATASET\n",
      "0\n",
      "lppd\n",
      "-0.4646786828113344\n",
      "0.03622177235858744\n",
      "mse\n",
      "0.13620489835314536\n",
      "0.011679005470384616\n",
      "pa\n",
      "83.26\n",
      "1.7579533554676536\n",
      "time\n",
      "7.261233854293823\n",
      "1.0526007804061877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FOR DATASET\n",
      "1\n",
      "lppd\n",
      "-0.1325502102866053\n",
      "0.0010226552585402247\n",
      "mse\n",
      "0.03381235404125658\n",
      "0.00029862623614619556\n",
      "pa\n",
      "95.99999999999999\n",
      "0.1414213562373115\n",
      "time\n",
      "7.261233854293823\n",
      "1.0526007804061877\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FOR DATASET\n",
      "2\n",
      "lppd\n",
      "-0.9105903865010376\n",
      "0.07570394990393282\n",
      "mse\n",
      "0.3181083916144147\n",
      "0.026192267010158497\n",
      "pa\n",
      "50.56\n",
      "4.277662913320776\n",
      "time\n",
      "7.261233854293823\n",
      "1.0526007804061877\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval(x_test, y_test, N_test):\n",
    "    #par=dataset\n",
    "    #Load test data\n",
    "    K_set=len(y_test)\n",
    "    \n",
    "    \n",
    "    lppd = np.zeros([n_iter,K_set])\n",
    "    mse = np.zeros([n_iter,K_set])\n",
    "    predcor = np.zeros([n_iter,K_set])\n",
    "    time = np.zeros([n_iter,K_set])\n",
    "    card = np.zeros([n_iter,K_set])\n",
    "    \n",
    "    \n",
    "    D,c,eps = 2, 0, 1e-1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(n_iter):\n",
    "        par = pd.read_pickle('./parameters/par_bb_logreg_c{}_a{}_b{}_gN_pol_B1000_seed{}'.format(0,1,1,100+i))\n",
    "        #Run through each seed to calculate predictive performance/times\n",
    "        #seed = 100+i\n",
    "        #y_test,x_test,N_test,D,c,pref,eps = load_data(dataset,seed)\n",
    "        BETA=[]\n",
    "        ALPHA=[]\n",
    "        time[i]=par['time']\n",
    "        for j in range(K_set):\n",
    "            BETA.append( par['beta'][j][:,0:2])\n",
    "            ALPHA.append(par['beta'][j][:,2])\n",
    "            \n",
    "            lppd[i,j]=lrl.lppd(y_test[j],x_test[j],BETA[j],ALPHA[j])\n",
    "            mse[i,j]=lrl.MSE(y_test[j],x_test[j],BETA[j],ALPHA[j])\n",
    "            predcor[i,j]= lrl.predcorrect(y_test[j],x_test[j],BETA[j],ALPHA[j])\n",
    "            mean_beta = np.mean(BETA[j],axis = 0)\n",
    "            card[i,j] = lrl.checkcard([mean_beta],eps)\n",
    "        \n",
    "        \n",
    "    #dict = {'lppd_1':lppd[0]/N_test[0], 'mse_1':mse[0], 'predcor_1': 100*predcor[0], 'card_1': ((D-card[0])/D)*100, 'time':time }\n",
    "\n",
    "    for j in range(K_set):\n",
    "        print('FOR DATASET')\n",
    "        print(j)\n",
    "        \n",
    "        print('lppd')\n",
    "        print(np.mean(lppd[:,j]/N_test[j]))\n",
    "        print(np.std(lppd[:,j]/N_test[j]))\n",
    "        \n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        print('mse')\n",
    "        print(np.mean(mse[:,j]))\n",
    "        print(np.std(mse[:,j]))\n",
    "\n",
    "        print('pa')\n",
    "        print(np.mean(100*predcor[:,j]))\n",
    "        print(np.std(100*predcor[:,j]))\n",
    "\n",
    "    \n",
    "        print('time')\n",
    "        print(np.mean(time))\n",
    "        print(np.std(time))\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#Run for 3 datasets from paper\n",
    "def main():\n",
    "    eval(X_test,y_test,[1000,1000,1000])\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pd.read_pickle('./parameters/par_bb_logreg_c{}_a{}_b{}_gN_pol_B1000_seed{}'.format(0,1,1,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_2=par[\"beta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(beta_2[2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(beta_2[2][:,0:2].flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_data=[100,200,500]\n",
    "X, y, gamma,eta = gen_toy(N_data, [np.array([-1,1]),np.array([-1,1]),np.array([-1,1])],2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.sum(yy) for yy in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(eta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X[1], y[1])\n",
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)[source]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n",
      "/Users/cuifuheng/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def adult_load(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    #import\n",
    "    ad_train = pd.read_csv('./data/adult.data',header = None)\n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "    ad_test = pd.read_csv('./data/adult.test', header = None)\n",
    "\n",
    "    #convert missing data to Nans\n",
    "    ad_train[ad_train == ' ?']= np.nan\n",
    "    ad_test[ad_test == ' ?']= np.nan\n",
    "\n",
    "    #drop missing categorical data\n",
    "    ad_train.dropna(axis = 0,inplace = True)\n",
    "    ad_test.dropna(axis = 0,inplace = True)\n",
    "\n",
    "    #separate covariates from classes\n",
    "    N_train = np.shape(ad_train)[0]\n",
    "    y_train = np.zeros(N_train)\n",
    "    y_train[ad_train.iloc[:,14] == ' >50K']=1\n",
    "    x_train = ad_train.iloc[:,0:14]\n",
    "\n",
    "    N_test = np.shape(ad_test)[0]\n",
    "    y_test = np.zeros(N_test)\n",
    "    y_test[ad_test.iloc[:,14] == ' >50K.']=1\n",
    "    x_test = ad_test.iloc[:,0:14]\n",
    "\n",
    "    #setup dummy\n",
    "    x_train =pd.get_dummies(x_train,drop_first = True,columns = [1,3,5,6,7,8,9,13])\n",
    "    x_test = pd.get_dummies(x_test,drop_first = True,columns = [1,3,5,6,7,8,9,13])    \n",
    "\n",
    "    #fix dummy difference\n",
    "    missing_cols = set( x_train.columns ) - set( x_test.columns)\n",
    "    for c in missing_cols:\n",
    "        x_test[c] = 0\n",
    "    x_test = x_test[x_train.columns]\n",
    "\n",
    "    D = np.shape(x_train)[1]\n",
    "    colnames = list(x_train.columns.values)\n",
    "\n",
    "    #concatenate and resplit\n",
    "    x = np.concatenate((x_train,x_test),axis = 0)\n",
    "    y = np.concatenate((y_train,y_test))\n",
    "    x_train,x_test, y_train,y_test = train_test_split(x,y,test_size = 0.2, stratify = y)\n",
    "    x_train = pd.DataFrame(x_train,columns = colnames)\n",
    "    x_test = pd.DataFrame(x_test, columns = colnames)\n",
    "    y_train = pd.DataFrame(y_train)\n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    \n",
    "    #import pdb\n",
    "    #pdb.set_trace()\n",
    "\n",
    "    N_train = np.shape(x_train)[0]\n",
    "    N_test = np.shape(x_test)[0]\n",
    "\n",
    "    #normalize by mean and std for non dummy variables\n",
    "    mean_train = x_train.mean(axis = 0)\n",
    "    std_train = x_train.std(axis = 0)\n",
    "    x_train[[0,2,4,10,11,12]] -= mean_train\n",
    "    x_train[[0,2,4,10,11,12]] /= std_train\n",
    "\n",
    "    mean_test = x_test[[0,2,4,10,11,12]].mean(axis = 0)\n",
    "    std_test = x_test[[0,2,4,10,11,12]].std(axis = 0)\n",
    "    x_test[[0,2,4,10,11,12]] -= mean_test\n",
    "    x_test[[0,2,4,10,11,12]] /= std_test\n",
    "\n",
    "    #convert binarys to uint8 to save space\n",
    "    y_train = y_train.astype('uint8')    \n",
    "    y_test = y_test.astype('uint8')\n",
    "\n",
    "    colnames2 = set(colnames) - set([0,2,4,10,11,12])\n",
    "    x_train[list(colnames2)] = x_train[list(colnames2)].astype('uint8') \n",
    "    x_test[list(colnames2)] = x_test[list(colnames2)].astype('uint8') \n",
    "\n",
    "    #Put into dictionary and save\n",
    "    ad_data_train= {'y': y_train, 'x': x_train, 'N':N_train,'D':D}\n",
    "    ad_data_test= {'y': y_test, 'x': x_test, 'N':N_test,'D':D}\n",
    "\n",
    "    with open('./data/ad_train_seed{}'.format(seed), 'wb') as handle:\n",
    "        pickle.dump(ad_data_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('./data/ad_test_seed{}'.format(seed), 'wb') as handle:\n",
    "        pickle.dump(ad_data_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    adult_load(100+i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 107.84it/s][A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 6968.44it/s]A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 209.41177582740784\n",
      "209.41177582740784\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "main script for running NPL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time\n",
    "from npl import bootstrap_logreg as bbl\n",
    "import pickle\n",
    "n_iter=1\n",
    "\n",
    "def load_data(seed):\n",
    "    #load adult\n",
    "    if True:\n",
    "        with open('./data/ad_train_seed{}'.format(seed), 'rb') as handle:\n",
    "            ad_train = pickle.load(handle)\n",
    "\n",
    "        #Move into vectors\n",
    "        y = np.uint8(ad_train['y'])[:,0]\n",
    "        x = ad_train['x'].values\n",
    "        D_data = ad_train['D']\n",
    "        N_data = ad_train['N']\n",
    "  \n",
    "\n",
    "        #prior and loss settings from paper\n",
    "        alph_conc = 0 \n",
    "        gamma = 1/N_data\n",
    "\n",
    "\n",
    "    return y,x,alph_conc,gamma,N_data,D_data\n",
    "\n",
    "\n",
    "\n",
    "def main(B_postsamples):\n",
    "    #same parameters between datasets\n",
    "    T_trunc = 100\n",
    "    a=1\n",
    "    b = 1 #rate of gamma hyperprior\n",
    "    \n",
    "    \n",
    "    alpha_top_layer=0\n",
    "    alph_conc=0\n",
    "    \n",
    "    \n",
    "    K_set=2\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        seed = 100+i\n",
    "        np.random.seed(seed)\n",
    "        y,x,_,_,N_data,D_data = load_data(seed)\n",
    "        \n",
    "        x_m=x[x[:,55]==1,:]\n",
    "        x_f=x[x[:,55]==0,:]\n",
    "        \n",
    "        y_m=y[x[:,55]==1]\n",
    "        y_f=y[x[:,55]==0]\n",
    "        \n",
    "        N_data=[int(sum(x[:,55]==1)),int(sum(x[:,55]==0))]\n",
    "        y=[y_m,y_f]\n",
    "        x=[x_m,x_f]\n",
    "        \n",
    "        gamma=[1/N_data[0],1/N_data[1]]\n",
    "    \n",
    "\n",
    "        start= time.time()\n",
    "        #carry out posterior bootstrap\n",
    "        temp = bbl.bootstrap_logreg(B_postsamples,alph_conc,alpha_top_layer,T_trunc,y,x,N_data,D_data,a,b,gamma)\n",
    "        end = time.time()\n",
    "        print ('Time elapsed = {}'.format(end - start))\n",
    "        \n",
    "        \n",
    "        \n",
    "        beta_bb=[]\n",
    "        ll_bb=[]\n",
    "        \n",
    "        for j in range(K_set):\n",
    "            beta_b=np.zeros((B_postsamples,D_data+1))\n",
    "            ll_b=[]\n",
    "            for bb in range(B_postsamples):\n",
    "                beta_b[bb]=temp[j][bb][0]\n",
    "                ll_b.append(temp[j][bb][1])\n",
    "            beta_bb.append(beta_b)\n",
    "            ll_bb.append(ll_b)\n",
    "        \n",
    "        \n",
    "\n",
    "        #convert to dataframe and save\n",
    "        dict_bb = {'beta': beta_bb, 'll': ll_bb, 'time': end-start}\n",
    "        par_bb = pd.Series(data = dict_bb)\n",
    "        print(par_bb['time'])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        if True:\n",
    "            par_bb.to_pickle('./parameters/par_ad_bb_logreg_c{}_a{}_b{}_gN_ad_B{}_seed{}'.format(alph_conc,a,b,B_postsamples,seed))\n",
    "\n",
    "        \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(20)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 55 male =1 felmale =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
